# LLM_Models
Towards a Foundation Model for Chest X-Ray Interpretation Vision Language Models 


ğŸ¦™ LLaMA 3.2 Vision Fine-Tuning with Unsloth (X-rays)

This repository contains a Jupyter Notebook for fine-tuning LLaMA 3.2 Vision models on X-ray datasets using the Unsloth
 library.
It demonstrates how to adapt multimodal large language models for medical imaging tasks such as classification, captioning, and report generation.

ğŸ“Œ Features

Fine-tuning LLaMA 3.2 Vision with Unsloth
 for efficient training.

X-ray image dataset integration (configurable for your own dataset).

Supports LoRA/QLoRA for parameter-efficient adaptation.

Evaluation metrics for classification and/or captioning.

Example inference for visual question answering (VQA) on medical images.

ğŸš€ Getting Started
1. Clone the file

2. Install dependencies

pip install unsloth transformers datasets accelerate peft bitsandbytes

3. Prepare your dataset

Prepare your X-ray dataset.

Dataset format should include images and corresponding labels/text.

Example datasets: ChestX-ray14 or MIMIC-CXR
4. Run the notebook

Launch Jupyter:

jupyter notebook


and open Llama_3_2_Vision_Finetuning_Unsloth_Xrays.ipynb.

ğŸ“Š Example Results

Fine-tuned model performance on validation set (accuracy / BLEU / ROUGE depending on task).

Example inference on unseen X-ray images:

âœ… â€œNormal Chest X-rayâ€

âš ï¸ â€œFindings suggest pneumoniaâ€

âš™ï¸ Project Structure
.
â”œâ”€â”€ Llama_3_2_Vision_Finetuning_Unsloth_Xrays.ipynb   # Main training notebook
â”œâ”€â”€ data/                                             # X-ray dataset (user-provided)
â”œâ”€â”€ outputs/                                          # Saved models, logs, checkpoints
â”œâ”€â”€ README.md                                         # Project documentation

ğŸ› ï¸ Tech Stack

Unsloth

Hugging Face Transformers

PEFT / LoRA

PyTorch

Accelerate

ğŸ“– Acknowledgements

UnslothAI
 for efficient fine-tuning framework.

Hugging Face ecosystem.

Open datasets like NIH ChestX-ray14 and MIMIC-CXR.

ğŸ”’ Disclaimer

This project is for research and educational purposes only.
