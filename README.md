# LLaMA 3.2 Vision for Chest X-Ray Interpretation

---

ğŸ« **What if an AI could read a chest X-ray and generate a clinical report â€” in seconds?**

That's not science fiction anymore. I just built it.

I've been working on fine-tuning **LLaMA 3.2 Vision** â€” Meta's latest multimodal large language model â€” specifically for **chest X-ray interpretation**. The result is a model that can look at a chest X-ray and produce clinically meaningful outputs: classifications, findings descriptions, and full radiology-style reports.

---

**Why this matters:**

There are over **2 billion chest X-rays** performed globally every year. Yet radiologist shortages mean reads are delayed â€” sometimes by hours in critical cases. In low-resource settings, some X-rays never get formally read at all.

A fine-tuned Vision-Language Model doesn't replace a radiologist. But it can:

ğŸ“‹ Generate a first-pass report for radiologist review
ğŸš¨ Flag high-priority findings for faster triage
ğŸŒ Bring diagnostic support to under-resourced hospitals
ğŸ“š Serve as a teaching tool for medical students

---

**What I built:**

A complete fine-tuning pipeline for **LLaMA 3.2 Vision** on chest X-ray datasets using the **Unsloth** framework â€” achieving fast, memory-efficient training through **LoRA/QLoRA** parameter-efficient adaptation.

The model supports three task modes:
ğŸ”¹ **Classification** â€” Normal / Pneumonia / Pleural Effusion / etc.
ğŸ”¹ **Captioning** â€” Generate a descriptive findings summary
ğŸ”¹ **Visual QA** â€” Answer clinical questions about an X-ray

Example outputs from fine-tuned inference:
âœ… *"Normal chest X-ray. No acute cardiopulmonary findings."*
âš ï¸ *"Findings suggest right lower lobe pneumonia. Recommend clinical correlation."*
ğŸ”´ *"Large left pleural effusion noted. Urgent evaluation advised."*

---

**Tech stack:**
ğŸ¦™ **LLaMA 3.2 Vision** â€” Meta's multimodal foundation model
âš¡ **Unsloth** â€” 2Ã— faster fine-tuning, 60% less VRAM
ğŸ¤— **Hugging Face Transformers + PEFT** â€” LoRA/QLoRA adaptation
ğŸ”¥ **PyTorch + Accelerate** â€” distributed training support
ğŸ“Š **ChestX-ray14 / MIMIC-CXR** â€” open medical imaging datasets

---

**What makes this technically significant:**

Fine-tuning a Vision-Language Model for medical imaging is non-trivial. Medical images require the model to understand both **visual pathology patterns** AND **clinical language** simultaneously. LoRA allows us to adapt an 11B parameter model on a single GPU â€” making this accessible to researchers without massive compute budgets.

This is part of a broader push toward **Foundation Models for Medical Imaging** â€” general-purpose models pre-trained at scale, then efficiently adapted for specific clinical tasks.

---

ğŸ”— Full notebook and code on GitHub â€” link in comments.

If you're working in medical AI, radiology informatics, or multimodal LLMs â€” I'd love to connect and discuss where this technology is headed.

#MedicalAI #LLM #LLaMA #VisionLanguageModel #ChestXray #Radiology #HealthcareAI #MultimodalAI #DeepLearning #FoundationModels #LoRA #QLoRA #Unsloth #AIinHealthcare #MedicalImaging #NLP #ComputerVision #HuggingFace #GenerativeAI #ClinicalAI

---
---

## ğŸ¯ Overview

This repository demonstrates how to fine-tune **Meta's LLaMA 3.2 Vision** on chest X-ray datasets for three clinical tasks:

- ğŸ” **Classification** â€” Identify pathologies (Pneumonia, Effusion, Atelectasis, Normal, etc.)
- ğŸ“ **Report Generation** â€” Produce radiology-style findings descriptions
- ğŸ’¬ **Visual Question Answering (VQA)** â€” Answer clinical questions about X-ray findings

Using **Unsloth**, training is **2Ã— faster** with **60% less VRAM** than standard fine-tuning â€”
making this accessible on a single consumer or research GPU.

---

## ğŸŒ Motivation

> There are over **2 billion chest X-rays** performed globally every year.

Radiologist shortages create dangerous delays â€” particularly in low-resource settings.
Vision-Language Models fine-tuned on medical imaging data offer a path toward:

- Automated first-pass report generation for radiologist review
- High-priority finding flagging for faster clinical triage
- Diagnostic support in under-resourced healthcare systems
- Medical education and training assistance

**This project is a research demonstration â€” not a clinical product.**

---

## âœ¨ Features

- âœ… **LLaMA 3.2 Vision fine-tuning** with Unsloth for efficient multimodal training
- âœ… **LoRA / QLoRA** â€” adapt an 11B model on a single GPU
- âœ… **Medical dataset integration** â€” ChestX-ray14, MIMIC-CXR, or custom datasets
- âœ… **Three task modes** â€” classification, captioning, visual QA
- âœ… **Evaluation metrics** â€” Accuracy, BLEU, ROUGE
- âœ… **End-to-end inference** â€” raw X-ray image to clinical text output

---

## ğŸ§  Pipeline

```
Chest X-Ray Image
      â†“
LLaMA 3.2 Vision Encoder (frozen)
      â†“
Cross-Modal Attention â€” Image + Text
      â†“
LoRA-adapted Language Model Head
      â†“
Clinical Text Output
  â†’ "No acute cardiopulmonary findings."
  â†’ "Right lower lobe pneumonia. Clinical correlation recommended."
  â†’ "Large left pleural effusion. Urgent evaluation advised."
```

**LoRA Config:**
- Rank r=16 | Target: q_proj, v_proj, k_proj, o_proj
- 4-bit QLoRA quantization
- ~1â€“2% trainable parameters of total model

---

## ğŸ“Š Example Outputs

| X-Ray Finding | Model Output |
|---------------|-------------|
| Normal PA film | âœ… "Normal chest X-ray. No acute findings identified." |
| Lower lobe opacity | âš ï¸ "Right lower lobe consolidation consistent with pneumonia." |
| Left fluid collection | ğŸ”´ "Large left pleural effusion with compressive atelectasis." |
| Enlarged heart | âš ï¸ "Increased cardiac silhouette suggestive of cardiomegaly." |

---

## ğŸš€ Quick Start

```bash
# 1. Clone
git clone https://github.com/your-username/llm-chest-xray.git
cd llm-chest-xray

# 2. Install
pip install unsloth transformers datasets accelerate peft bitsandbytes

# 3. Open notebook
jupyter notebook Llama_3_2_Vision_Finetuning_Unsloth_Xrays.ipynb
```

**Dataset format:**
```python
{
  "image": "path/to/xray.jpg",
  "label": "Pneumonia",
  "report": "Findings suggest right lower lobe consolidation..."
}
```

Supported datasets: [NIH ChestX-ray14](https://nihcc.app.box.com/v/ChestXray-NIHCC) Â· [MIMIC-CXR](https://physionet.org/content/mimic-cxr/)

---

## ğŸ“ Project Structure

```
llm-chest-xray/
â”œâ”€â”€ Llama_3_2_Vision_Finetuning_Unsloth_Xrays.ipynb   # Main notebook
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train/                                          # Training images
â”‚   â”œâ”€â”€ val/                                            # Validation images
â”‚   â””â”€â”€ dataset.json                                    # Labels / reports
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ checkpoint-*/                                   # LoRA checkpoints
â”‚   â””â”€â”€ logs/
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|-----------|
| Base Model | LLaMA 3.2 Vision (Meta) |
| Fine-tuning | Unsloth â€” 2Ã— faster, 60% less VRAM |
| Adaptation | PEFT / LoRA / QLoRA (Hugging Face) |
| Framework | PyTorch + Accelerate |
| Pipelines | Hugging Face Transformers |
| Datasets | ChestX-ray14, MIMIC-CXR |

---

## ğŸ”® Roadmap

| Version | Feature |
|---------|---------|
| v1.0 | Fine-tuning notebook â€” classification + captioning âœ… |
| v1.1 | Full MIMIC-CXR report generation pipeline |
| v1.2 | Multi-label pathology classification |
| v2.0 | Flask web app â€” upload X-ray, get AI report |
| v2.1 | DICOM (.dcm) file support |
| v2.2 | GradCAM visual explanation overlays |
| v3.0 | Benchmark: LLaMA vs BioViL vs CheXagent vs MedPaLM |
| v3.1 | RLHF with radiologist feedback |

---

## âš ï¸ Disclaimer

This project is **strictly for research and educational purposes**.
It is **not validated for clinical use** and must **not** be used to make or influence
medical decisions. All outputs require review by a qualified radiologist or physician.

---

## ğŸ“– Acknowledgements

- [UnslothAI](https://github.com/unslothai/unsloth) â€” efficient fine-tuning framework
- [Hugging Face](https://huggingface.co) â€” Transformers, PEFT, Datasets
- [NIH Clinical Center](https://nihcc.app.box.com/v/ChestXray-NIHCC) â€” ChestX-ray14
- [PhysioNet / MIT](https://physionet.org/content/mimic-cxr/) â€” MIMIC-CXR
- [Meta AI](https://ai.meta.com/llama/) â€” LLaMA 3.2 Vision

---

## ğŸ¤ Open to Collaboration

Looking to connect with:
- ğŸ¥ Radiologists interested in AI-assisted reporting
- ğŸ§¬ Medical AI researchers working on foundation models
- ğŸ¤— VLM researchers pushing multimodal medical AI
- ğŸš€ Healthcare startups building clinical AI products
- ğŸŒ Global health technologists expanding diagnostic access

**Let's build medical AI that actually helps people.**

---

## ğŸ“œ License

MIT License â€” open for research and educational use with attribution.

---

â­ Star Â· ğŸ´ Fork Â· ğŸ’¬ Contribute Â· ğŸ“¤ Share

<p align="center">Built with â¤ï¸ for the future of medical AI Â· <b>Mansoor Ahmad</b> Â· AI & Robotics Engineer Â· NSTP Islamabad</p>
```
```
Chest X-Ray Image
      â†“
LLaMA 3.2 Vision Encoder (frozen)
      â†“
Cross-Modal Attention â€” Image + Text
      â†“
LoRA-adapted Language Model Head
      â†“
Clinical Text Output
  â†’ "No acute cardiopulmonary findings."
  â†’ "Right lower lobe pneumonia. Clinical correlation recommended."
  â†’ "Large left pleural effusion. Urgent evaluation advised."
```

**LoRA Config:**
- Rank r=16 | Target: q_proj, v_proj, k_proj, o_proj
- 4-bit QLoRA quantization
- ~1â€“2% trainable parameters of total model

---

## ğŸ“Š Example Outputs

| X-Ray Finding | Model Output |
|---------------|-------------|
| Normal PA film | âœ… "Normal chest X-ray. No acute findings identified." |
| Lower lobe opacity | âš ï¸ "Right lower lobe consolidation consistent with pneumonia." |
| Left fluid collection | ğŸ”´ "Large left pleural effusion with compressive atelectasis." |
| Enlarged heart | âš ï¸ "Increased cardiac silhouette suggestive of cardiomegaly." |

---

## ğŸš€ Quick Start

```bash
# 1. Clone
git clone https://github.com/your-username/llm-chest-xray.git
cd llm-chest-xray

# 2. Install
pip install unsloth transformers datasets accelerate peft bitsandbytes

# 3. Open notebook
jupyter notebook Llama_3_2_Vision_Finetuning_Unsloth_Xrays.ipynb
```

**Dataset format:**
```python
{
  "image": "path/to/xray.jpg",
  "label": "Pneumonia",
  "report": "Findings suggest right lower lobe consolidation..."
}
```

Supported datasets: [NIH ChestX-ray14](https://nihcc.app.box.com/v/ChestXray-NIHCC) Â· [MIMIC-CXR](https://physionet.org/content/mimic-cxr/)

---

## ğŸ“ Project Structure

```
llm-chest-xray/
â”œâ”€â”€ Llama_3_2_Vision_Finetuning_Unsloth_Xrays.ipynb   # Main notebook
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train/                                          # Training images
â”‚   â”œâ”€â”€ val/                                            # Validation images
â”‚   â””â”€â”€ dataset.json                                    # Labels / reports
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ checkpoint-*/                                   # LoRA checkpoints
â”‚   â””â”€â”€ logs/
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|-----------|
| Base Model | LLaMA 3.2 Vision (Meta) |
| Fine-tuning | Unsloth â€” 2Ã— faster, 60% less VRAM |
| Adaptation | PEFT / LoRA / QLoRA (Hugging Face) |
| Framework | PyTorch + Accelerate |
| Pipelines | Hugging Face Transformers |
| Datasets | ChestX-ray14, MIMIC-CXR |

---

## ğŸ”® Roadmap

| Version | Feature |
|---------|---------|
| v1.0 | Fine-tuning notebook â€” classification + captioning âœ… |
| v1.1 | Full MIMIC-CXR report generation pipeline |
| v1.2 | Multi-label pathology classification |
| v2.0 | Flask web app â€” upload X-ray, get AI report |
| v2.1 | DICOM (.dcm) file support |
| v2.2 | GradCAM visual explanation overlays |
| v3.0 | Benchmark: LLaMA vs BioViL vs CheXagent vs MedPaLM |
| v3.1 | RLHF with radiologist feedback |

---

## âš ï¸ Disclaimer

This project is **strictly for research and educational purposes**.
It is **not validated for clinical use** and must **not** be used to make or influence
medical decisions. All outputs require review by a qualified radiologist or physician.

---

## ğŸ“– Acknowledgements

- [UnslothAI](https://github.com/unslothai/unsloth) â€” efficient fine-tuning framework
- [Hugging Face](https://huggingface.co) â€” Transformers, PEFT, Datasets
- [NIH Clinical Center](https://nihcc.app.box.com/v/ChestXray-NIHCC) â€” ChestX-ray14
- [PhysioNet / MIT](https://physionet.org/content/mimic-cxr/) â€” MIMIC-CXR
- [Meta AI](https://ai.meta.com/llama/) â€” LLaMA 3.2 Vision

---

## ğŸ¤ Open to Collaboration

Looking to connect with:
- ğŸ¥ Radiologists interested in AI-assisted reporting
- ğŸ§¬ Medical AI researchers working on foundation models
- ğŸ¤— VLM researchers pushing multimodal medical AI
- ğŸš€ Healthcare startups building clinical AI products
- ğŸŒ Global health technologists expanding diagnostic access

**Let's build medical AI that actually helps people.**

---

## ğŸ“œ License

MIT License â€” open for research and educational use with attribution.

---

â­ Star Â· ğŸ´ Fork Â· ğŸ’¬ Contribute Â· ğŸ“¤ Share





